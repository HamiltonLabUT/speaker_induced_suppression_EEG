{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c00c3cf9",
   "metadata": {},
   "source": [
    "## Within subject statistics\n",
    "AKA, Wilcoxon signed-rank tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aee7f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from scipy.stats import wilcoxon\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from glob import glob\n",
    "import csv\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "sys.path.append('../preprocessing/utils/')\n",
    "import strf\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "from matplotlib import rcParams as rc\n",
    "rc['pdf.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb09796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these path for running the notebook locally\n",
    "eeg_data_path = '/path/to/dataset/' # downloadable from OSF: https://doi.org/10.17605/OSF.IO/FNRD9\n",
    "git_path  = '/path/to/git/speaker_induced_suppression_EEG/'\n",
    "# Where the output of train_linear_model.ipynb is saved. Run that first if you haven't already.\n",
    "h5_path = '/path/to/h5/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4606ce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "picks = ['F1','Fz','F2','FC1','FCz','FC2','C1','Cz','C2']\n",
    "tmin,tmax = -1.5, 3.5\n",
    "baseline=(None,0)\n",
    "reject_thresh = 10 # SD\n",
    "exclude = 'OP0020'\n",
    "subjs = np.sort([s[-6:] for s in glob(f'{git_path}eventfiles/*') if 'OP0' in s and exclude not in s])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9b334f",
   "metadata": {},
   "source": [
    "## Load ERP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d2c465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_bads(subj,block,raw,git_path,eeg_data_path):\n",
    "    '''\n",
    "    CCA .vhdr files do not include bad channels, so this func interpolates them.\n",
    "    The end result is each subject has a 64 channel raw arrray, which makes plotting easier\n",
    "    Filter the data before running this!\n",
    "    '''\n",
    "    blockid = subj + '_' + block\n",
    "    nsamps = len(raw)\n",
    "    info = mne.io.read_raw_brainvision(f'{eeg_data_path}OP0001/OP0001_B1/OP0001_B1_cca.vhdr',\n",
    "                                           preload=False,verbose=False).info\n",
    "    ch_names = info['ch_names']\n",
    "    bads = [c for c in ch_names if c not in raw.info['ch_names']]\n",
    "    if len(bads) > 0:\n",
    "        new_data = []\n",
    "        for ch in ch_names:\n",
    "            if ch in bads:\n",
    "                print('Interpolating', ch)\n",
    "                new_data.append(np.zeros((1,nsamps)))\n",
    "            else:\n",
    "                new_data.append(raw.get_data(picks=ch)[0])\n",
    "        raw = mne.io.RawArray(np.vstack(new_data),info)\n",
    "        raw.info['bads'] = bads\n",
    "        raw.interpolate_bads()\n",
    "    else:\n",
    "        print(subj, 'has no bads.')\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0018aca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raws, spkr_epochs, mic_epochs, spkr_resp, mic_resp = dict(), dict(), dict(), dict(), dict()\n",
    "conditions = ['el','sh','all']\n",
    "channels = ['spkr', 'mic']\n",
    "conditions\n",
    "subj_bar = tqdm(subjs)\n",
    "for s in subj_bar:\n",
    "    spkr_epochs[s], mic_epochs[s], spkr_resp[s], mic_resp[s] = dict(), dict(), dict(), dict()\n",
    "    if s != 'OP0002':\n",
    "        block = 'B1'\n",
    "    else:\n",
    "        block = 'B2'\n",
    "    blockid = s + '_' + block\n",
    "    raw_path = f'{eeg_data_path}{s}/{blockid}/{blockid}_cca.vhdr'\n",
    "    raw = mne.io.read_raw_brainvision(raw_path,preload=True,verbose=False)\n",
    "    raw.filter(l_freq=1,h_freq=30,verbose=False)\n",
    "    raws[s] = interpolate_bads(s,block,raw,git_path,eeg_data_path)\n",
    "    for ch in channels:\n",
    "        spkr_epochs[s][ch], mic_epochs[s][ch], spkr_resp[s][ch], mic_resp[s][ch] = dict(), dict(), dict(), dict()\n",
    "        for co in conditions:\n",
    "            subj_bar.set_description(f'Epoching {s} {ch} {co}')\n",
    "            if s in ['OP0015','OP0016']: # mtpl blocks\n",
    "                events = []\n",
    "                for b in ['B1','B2']: \n",
    "                    event_file = f'{git_path}eventfiles/{s}/{s}_{b}/{s}_{b}_{ch}_sn_{co}.txt'\n",
    "                    if b == 'B2':\n",
    "                        b2_fpath = raw_path = f'{eeg_data_path}{s}/{s}_B1/{s}_B1_downsampled.vhdr'\n",
    "                        b2_raw = mne.io.read_raw_brainvision(b2_fpath,preload=True,verbose=False)\n",
    "                        block_shift = b2_raw.last_samp\n",
    "                    else:\n",
    "                        block_shift = 0\n",
    "                    with open(event_file, 'r') as my_csv:\n",
    "                        csvReader = csv.reader(my_csv, delimiter='\\t')\n",
    "                        for row in csvReader:\n",
    "                            onset = int((float(row[0])*128)+block_shift)\n",
    "                            offset = int((float(row[1])*128)+block_shift)\n",
    "                            sn_id = int(row[2])\n",
    "                            events.append([onset,offset,sn_id])\n",
    "                events = np.array(events,dtype=int)\n",
    "            else:\n",
    "                event_file = f'{git_path}eventfiles/{s}/{blockid}/{blockid}_{ch}_sn_{co}.txt'\n",
    "                events = []\n",
    "                with open(event_file, 'r') as my_csv:\n",
    "                    csvReader = csv.reader(my_csv, delimiter='\\t')\n",
    "                    for row in csvReader:\n",
    "                        onset = int((float(row[0])*128))\n",
    "                        offset = int((float(row[1])*128))\n",
    "                        sn_id = int(row[2])\n",
    "                        events.append([onset,offset,sn_id])\n",
    "                events = np.array(events,dtype=int)\n",
    "            reject = mne.Epochs(raws[s], events, tmin=tmin, tmax=tmax,reject=None,\n",
    "                           baseline=baseline,verbose=False)\n",
    "            reject = reject.get_data(picks=picks)\n",
    "            reject = dict(eeg=np.std(reject)*(reject_thresh*2))\n",
    "            epochs = mne.Epochs(raws[s],events,tmin=tmin,tmax=tmax,reject=reject,\n",
    "                                   baseline=baseline,verbose=False)\n",
    "            if ch == 'spkr':\n",
    "                spkr_epochs[s][ch][co] = epochs\n",
    "                spkr_resp[s][ch][co] = epochs.get_data(picks=picks)\n",
    "            if ch == 'mic':\n",
    "                mic_epochs[s][ch][co] = epochs\n",
    "                mic_resp[s][ch][co] = epochs.get_data(picks=picks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1b28df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get n100 and P200 info \n",
    "N100_window = [0.08,0.15]\n",
    "P200_window = [0.15,0.25]\n",
    "t = np.linspace(tmin,tmax,spkr_resp[s]['spkr']['all'].shape[2])\n",
    "N100_inds = np.where((t>N100_window[0]) & (t<N100_window[1]))[0]\n",
    "P200_inds = np.where((t>P200_window[0]) & (t<P200_window[1]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be8626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "N100_el_peak_amplitude,N100_sh_peak_amplitude = dict(),dict()\n",
    "P200_el_peak_amplitude,P200_sh_peak_amplitude = dict(),dict()\n",
    "N100_el_peak_latency,N100_sh_peak_latency = dict(),dict()\n",
    "P200_el_peak_latency,P200_sh_peak_latency = dict(),dict()\n",
    "peak_to_peak_el,peak_to_peak_sh = dict(),dict()\n",
    "for subj in subjs:\n",
    "    if subj !='OP0015':\n",
    "        # el\n",
    "        N100_el_peak_amplitude[subj] = spkr_resp[subj]['spkr']['el'].mean(1)[:,N100_inds].min(1) # amplitude\n",
    "        latency_idx = N100_inds[spkr_resp[subj]['spkr']['el'].mean(1)[:,N100_inds].argmin(1)] # latency\n",
    "        N100_el_peak_latency[subj] = t[latency_idx]\n",
    "        P200_el_peak_amplitude[subj] = spkr_resp[subj]['spkr']['el'].mean(1)[:,P200_inds].max(1) # amplitude\n",
    "        latency_idx = P200_inds[spkr_resp[subj]['spkr']['el'].mean(1)[:,P200_inds].argmax(1)] # latency\n",
    "        P200_el_peak_latency[subj] = t[latency_idx]\n",
    "        peak_to_peak_el[subj] = np.abs(\n",
    "            P200_el_peak_amplitude[subj] - N100_el_peak_amplitude[subj])\n",
    "        # sh\n",
    "        N100_sh_peak_amplitude[subj] = spkr_resp[subj]['spkr']['sh'].mean(1)[:,N100_inds].min(1) # amplitude\n",
    "        latency_idx = N100_inds[spkr_resp[subj]['spkr']['sh'].mean(1)[:,N100_inds].argmin(1)] # latency\n",
    "        N100_sh_peak_latency[subj] = t[latency_idx]\n",
    "        P200_sh_peak_amplitude[subj] = spkr_resp[subj]['spkr']['sh'].mean(1)[:,P200_inds].max(1) # amplitude\n",
    "        latency_idx = P200_inds[spkr_resp[subj]['spkr']['sh'].mean(1)[:,P200_inds].argmax(1)] # latency\n",
    "        P200_sh_peak_latency[subj] = t[latency_idx]\n",
    "        peak_to_peak_sh[subj] = np.abs(\n",
    "            P200_sh_peak_amplitude[subj] - N100_sh_peak_amplitude[subj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9882a656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make el and sh the same length for wilcoxon\n",
    "for subj in subjs:\n",
    "    if subj != 'OP0015':\n",
    "        el_len = N100_el_peak_amplitude[subj].shape[0]\n",
    "        sh_len = N100_sh_peak_amplitude[subj].shape[0]\n",
    "#         print(\"%s #echo epochs: %d; #shuff epochs: %d\" % (subj, el_len, sh_len))\n",
    "        n_epochs = np.min((el_len,sh_len))\n",
    "        N100_el_peak_amplitude[subj] = N100_el_peak_amplitude[subj][:n_epochs]\n",
    "        N100_sh_peak_amplitude[subj] = N100_sh_peak_amplitude[subj][:n_epochs]\n",
    "        P200_el_peak_amplitude[subj] = P200_el_peak_amplitude[subj][:n_epochs]\n",
    "        P200_sh_peak_amplitude[subj] = P200_sh_peak_amplitude[subj][:n_epochs]\n",
    "        N100_el_peak_latency[subj] = N100_el_peak_latency[subj][:n_epochs]\n",
    "        N100_sh_peak_latency[subj] = N100_sh_peak_latency[subj][:n_epochs]\n",
    "        P200_el_peak_latency[subj] = P200_el_peak_latency[subj][:n_epochs]\n",
    "        P200_sh_peak_latency[subj] = P200_sh_peak_latency[subj][:n_epochs]\n",
    "        peak_to_peak_el[subj] = peak_to_peak_el[subj][:n_epochs]\n",
    "        peak_to_peak_sh[subj] = peak_to_peak_sh[subj][:n_epochs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3350f00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N100_amp_pval, N100_lat_pval, P200_amp_pval, P200_lat_pval = dict(), dict(), dict(), dict()\n",
    "p2p_pval = dict()\n",
    "for subj in subjs:\n",
    "    if subj != 'OP0015':\n",
    "        stat, N100_amp_pval[subj] = wilcoxon(\n",
    "            N100_el_peak_amplitude[subj],N100_sh_peak_amplitude[subj])\n",
    "        reject, N100_amp_pval[subj], alphacSidak,alphacBonf = multipletests(\n",
    "            N100_amp_pval[subj],alpha=0.05,method='fdr_by')\n",
    "        # N100 latency\n",
    "        stat, N100_lat_pval[subj] = wilcoxon(\n",
    "            N100_el_peak_latency[subj],N100_sh_peak_latency[subj])\n",
    "        reject, N100_lat_pval[subj], alphacSidak,alphacBonf = multipletests(\n",
    "            N100_lat_pval[subj],alpha=0.05,method='fdr_by')\n",
    "        # P200 amplitude\n",
    "        stat, P200_amp_pval[subj] = wilcoxon(\n",
    "            P200_el_peak_amplitude[subj],P200_sh_peak_amplitude[subj])\n",
    "        reject, P200_amp_pval[subj], alphacSidak,alphacBonf = multipletests(\n",
    "            P200_amp_pval[subj],alpha=0.05,method='fdr_by')\n",
    "        # P200 latency\n",
    "        stat, P200_lat_pval[subj] = wilcoxon(\n",
    "            P200_el_peak_latency[subj],P200_sh_peak_latency[subj])\n",
    "        reject, P200_lat_pval[subj], alphacSidak,alphacBonf = multipletests(\n",
    "            P200_lat_pval[subj],alpha=0.05,method='fdr_by')\n",
    "        # Peak to peak\n",
    "        stat, p2p_pval[subj] = wilcoxon(\n",
    "            peak_to_peak_el[subj],peak_to_peak_sh[subj])\n",
    "        reject, p2p_pval[subj], alphacSidak,alphacBonf = multipletests(\n",
    "            p2p_pval[subj],alpha=0.05,method='fdr_by')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1586442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subj in subjs:\n",
    "    if subj != 'OP0015':\n",
    "        print(subj)\n",
    "        print(\"N100 amplitude:\", N100_amp_pval[subj][0])\n",
    "        print(\"N100 latency:\", N100_lat_pval[subj][0])\n",
    "        print(\"P200 amplitude:\", P200_amp_pval[subj][0])\n",
    "        print(\"P200 latency:\", P200_lat_pval[subj][0])\n",
    "        print(\"Peak to peak:\", p2p_pval[subj][0])\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6152ba95",
   "metadata": {},
   "source": [
    "## Load LEM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8782c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['model1','model1e','model2','model2e','model3','model3e','model4','model4e']\n",
    "exclude = ['OP0001','OP0002','OP0004','OP0017','OP0020']\n",
    "subjs = [s for s in subjs if s not in exclude]\n",
    "tmin,tmax = -0.3,0.5\n",
    "delays = np.arange(np.floor(tmin*128),np.ceil(tmax*128),dtype=int)\n",
    "features = {model_number:strf.get_feats(model_number,extend_labels=True) for model_number in models}\n",
    "n_feats = {model_number:len(features[model_number]) for model_number in models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceacf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from hdf5, pandas\n",
    "wts, corrs, pvals, sig_wts, sig_corrs, alphas = dict(), dict(), dict(), dict(), dict(), dict()\n",
    "results_csv_fpath = f\"{git_path}stats/lem_results.csv\"\n",
    "df = pd.read_csv(results_csv_fpath)\n",
    "for m in models:\n",
    "    wts[m], corrs[m], pvals[m], sig_wts[m], sig_corrs[m], alphas[m] = dict(), dict(), dict(), dict(), dict(), dict()\n",
    "    b = tqdm(subjs)\n",
    "    for s in b:\n",
    "        blockid = f\"{s}_B1\"\n",
    "        b.set_description(f'Loading STRF for {s} {m}')\n",
    "        with h5py.File(f\"{h5_path}{s}_weights.hdf5\",'r') as f:\n",
    "            wts[m][s] = np.array(f.get(m))\n",
    "        ch_names = mne.io.read_raw_brainvision(f\"{eeg_data_path}{s}/{blockid}/{blockid}_cca.vhdr\",\n",
    "                                               preload=False,verbose=False).info['ch_names']\n",
    "        subj_corrs, subj_best_alphas, subj_pvals = np.zeros(len(ch_names)), np.zeros(len(ch_names)), np.zeros(len(ch_names))\n",
    "        for i, ch in enumerate(ch_names):\n",
    "            tgt_row = df[(df['subject']==s) & (df['model']==m) & (df['channel']==ch)]\n",
    "            subj_corrs[i] = df.loc[tgt_row.index, 'r_value']\n",
    "            subj_best_alphas[i] = df.loc[tgt_row.index, 'best_alpha']\n",
    "            subj_pvals[i] = df.loc[tgt_row.index, 'p_value']\n",
    "        corrs[m][s] = np.array(subj_corrs)\n",
    "        pvals[m][s] = np.array(subj_pvals)\n",
    "        alphas[m][s] = np.array(subj_best_alphas)\n",
    "    # Extract significant weights, corrs\n",
    "    for s in subjs:\n",
    "        nchans = wts[m][s].shape[2]\n",
    "        sig_wts[m][s] = np.zeros((len(delays),n_feats[m],nchans))\n",
    "        sig_corrs[m][s] = np.zeros((nchans))\n",
    "        for i in np.arange(nchans):\n",
    "            if pvals[m][s][i] < 0.01:\n",
    "                sig_wts[m][s][i] = wts[m][s][i]\n",
    "                sig_corrs[m][s][i] = corrs[m][s][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cab09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMG regress vs no regress\n",
    "comparison = ['model1', 'model1e']\n",
    "plt.figure(figsize=(8,4))\n",
    "modelcomp_pvals = np.zeros((len(subjs)))\n",
    "for i,s in enumerate(subjs):\n",
    "    c1 = sig_corrs[comparison[0]][s]\n",
    "    c2 = sig_corrs[comparison[1]][s]\n",
    "    stat, modelcomp_pvals[i] = wilcoxon(c1, c2)\n",
    "    reject, modelcomp_pvals[i], alphacSidak, alphacBonf = multipletests(modelcomp_pvals[i],\n",
    "                                                                        alpha=0.05,method='fdr_by')\n",
    "    ylim = [0,0.03]\n",
    "    if modelcomp_pvals[i] < 0.05:\n",
    "        color = 'mediumseagreen'\n",
    "        alpha = 1\n",
    "    else:\n",
    "        color = 'firebrick'\n",
    "        alpha = 0.5\n",
    "        plt.text(i,np.mean(ylim),'n.s.', ha='center', style='italic',weight='heavy',color='w',fontsize=12)\n",
    "    plt.bar(i,modelcomp_pvals[i],color=color,alpha=alpha)\n",
    "plt.gca().set_ylim(ylim)\n",
    "plt.gca().set_yticks(np.linspace(ylim[0],ylim[1],5))\n",
    "plt.gca().set_yticklabels(np.linspace(ylim[0],ylim[1],5),fontsize=12)\n",
    "plt.gca().set_xticks(np.arange(len(subjs)))\n",
    "plt.gca().set_xticklabels(subjs,rotation='vertical',fontsize=12);\n",
    "plt.xlabel('Subject',fontsize=12)\n",
    "plt.ylabel('p value', fontsize=12);\n",
    "plt.title(f'Within-subject comparison of {comparison[0]} and {comparison[1]} \\nby multiple test-corrected Wilcoxon signed-rank test',fontsize=12);\n",
    "plt.tight_layout();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f7320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identical vs. differential phn feat encoding\n",
    "comparison = ['model1', 'model2']\n",
    "plt.figure(figsize=(8,4))\n",
    "modelcomp_pvals = np.zeros((len(subjs)))\n",
    "for i,s in enumerate(subjs):\n",
    "    c1 = sig_corrs[comparison[0]][s]\n",
    "    c2 = sig_corrs[comparison[1]][s]\n",
    "    stat, modelcomp_pvals[i] = wilcoxon(c1, c2)\n",
    "    reject, modelcomp_pvals[i], alphacSidak, alphacBonf = multipletests(modelcomp_pvals[i],\n",
    "                                                                        alpha=0.05,method='fdr_by')\n",
    "    ylim = [0,0.03]\n",
    "    if modelcomp_pvals[i] < 0.05:\n",
    "        color = 'mediumseagreen'\n",
    "        alpha = 1\n",
    "    else:\n",
    "        color = 'firebrick'\n",
    "        alpha = 0.5\n",
    "        plt.text(i,np.mean(ylim),'n.s.', ha='center', style='italic',weight='heavy',color='w',fontsize=12)\n",
    "    plt.bar(i,modelcomp_pvals[i],color=color,alpha=alpha)\n",
    "plt.gca().set_ylim(ylim)\n",
    "plt.gca().set_yticks(np.linspace(ylim[0],ylim[1],5))\n",
    "plt.gca().set_yticklabels(np.linspace(ylim[0],ylim[1],5),fontsize=12)\n",
    "plt.gca().set_xticks(np.arange(len(subjs)))\n",
    "plt.gca().set_xticklabels(subjs,rotation='vertical',fontsize=12);\n",
    "plt.xlabel('Subject',fontsize=12)\n",
    "plt.ylabel('p value', fontsize=12);\n",
    "plt.title(f'Within-subject comparison of {comparison[0]} and {comparison[1]} \\nby multiple test-corrected Wilcoxon signed-rank test',fontsize=12);\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d961ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding vs not encoding task predictability\n",
    "comparison = ['model1', 'model3']\n",
    "plt.figure(figsize=(8,4))\n",
    "modelcomp_pvals = np.zeros((len(subjs)))\n",
    "for i,s in enumerate(subjs):\n",
    "    c1 = sig_corrs[comparison[0]][s]\n",
    "    c2 = sig_corrs[comparison[1]][s]\n",
    "    stat, modelcomp_pvals[i] = wilcoxon(c1, c2)\n",
    "    reject, modelcomp_pvals[i], alphacSidak, alphacBonf = multipletests(modelcomp_pvals[i],\n",
    "                                                                        alpha=0.05,method='fdr_by')\n",
    "    ylim = [0,0.04]\n",
    "    if modelcomp_pvals[i] < 0.05:\n",
    "        color = 'mediumseagreen'\n",
    "        alpha = 1\n",
    "    else:\n",
    "        color = 'firebrick'\n",
    "        alpha = 0.5\n",
    "        plt.text(i,np.mean(ylim),'n.s.', ha='center', style='italic',weight='heavy',color='w',fontsize=12)\n",
    "    plt.bar(i,modelcomp_pvals[i],color=color,alpha=alpha)\n",
    "plt.gca().set_ylim(ylim)\n",
    "plt.gca().set_yticks(np.linspace(ylim[0],ylim[1],5))\n",
    "plt.gca().set_yticklabels(np.linspace(ylim[0],ylim[1],5),fontsize=12)\n",
    "plt.gca().set_xticks(np.arange(len(subjs)))\n",
    "plt.gca().set_xticklabels(subjs,rotation='vertical',fontsize=12);\n",
    "plt.xlabel('Subject',fontsize=12)\n",
    "plt.ylabel('p value', fontsize=12);\n",
    "plt.title(f'Within-subject comparison of {comparison[0]} and {comparison[1]} \\nby multiple test-corrected Wilcoxon signed-rank test',fontsize=12);\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a3dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding vs not encoding task modality\n",
    "comparison = ['model1', 'model4']\n",
    "plt.figure(figsize=(10,5))\n",
    "modelcomp_pvals = np.zeros((len(subjs)))\n",
    "for i,s in enumerate(subjs):\n",
    "    c1 = sig_corrs[comparison[0]][s]\n",
    "    c2 = sig_corrs[comparison[1]][s]\n",
    "    stat, modelcomp_pvals[i] = wilcoxon(c1, c2)\n",
    "    reject, modelcomp_pvals[i], alphacSidak, alphacBonf = multipletests(modelcomp_pvals[i],\n",
    "                                                                        alpha=0.05,method='fdr_by')\n",
    "    ylim = [0,0.03]\n",
    "    if modelcomp_pvals[i] < 0.05:\n",
    "        color = 'mediumseagreen'\n",
    "        alpha = 1\n",
    "    else:\n",
    "        color = 'firebrick'\n",
    "        alpha = 0.5\n",
    "        plt.text(i,np.mean(ylim),'n.s.', ha='center', style='italic',weight='heavy',color='w',fontsize=12)\n",
    "    plt.bar(i,modelcomp_pvals[i],color=color,alpha=alpha)\n",
    "plt.gca().set_ylim(ylim)\n",
    "plt.gca().set_yticks(np.linspace(ylim[0],ylim[1],5))\n",
    "plt.gca().set_yticklabels(np.linspace(ylim[0],ylim[1],5),fontsize=12)\n",
    "plt.gca().set_xticks(np.arange(len(subjs)))\n",
    "plt.gca().set_xticklabels(subjs,rotation='vertical',fontsize=12);\n",
    "plt.xlabel('Subject',fontsize=12)\n",
    "plt.ylabel('p value', fontsize=12);\n",
    "plt.title(f'Within-subject comparison of {comparison[0]} and {comparison[1]} \\nby multiple test-corrected Wilcoxon signed-rank test',fontsize=12);\n",
    "plt.tight_layout();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
