{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8446b702",
   "metadata": {},
   "source": [
    "## Bootstrap linear encoding models\n",
    "**Warning: this notebook is very computationally intensive.** You may wish to run it on your lab server instead of a local machine. Another alternative is to split the subjects up into smaller subsets, then run those subsets instead of holding all the subjects' models in memory at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c252392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import h5py\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools as itools\n",
    "import pandas as pd\n",
    "import sys\n",
    "from glob import glob\n",
    "sys.path.append('../preprocessing/utils/')\n",
    "from ridge import eigridge_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47442b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these path for running the notebook locally\n",
    "eeg_data_path = '/path/to/dataset/' # downloadable from OSF: https://doi.org/10.17605/OSF.IO/FNRD9\n",
    "git_path  = '/path/to/git/speaker_induced_suppression_EEG/'\n",
    "# Where the output of train_linear_model.ipynb is saved. Run that first if you haven't already.\n",
    "h5_path = '/path/to/h5/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e4a7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['model1']\n",
    "tmin, tmax = -0.3, 0.5\n",
    "nboots_shuffle = 100\n",
    "exclude = ['OP0001','OP0002','OP0004','OP0017','OP0020']\n",
    "subjs = np.sort([s[-6:] for s in glob(f'{git_path}eventfiles/*') if 'OP0' in s and s[-6:] not in exclude])\n",
    "delays = np.arange(np.floor(tmin*128),np.ceil(tmax*128),dtype=int)\n",
    "chunklen = len(delays)*3 # data randomized in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d732fe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stim/resp from hdf5\n",
    "tStims, tResps, vStims, vResps = dict(), dict(), dict(), dict()\n",
    "pbar = tqdm(subjs)\n",
    "for s in pbar:\n",
    "    pbar.set_description(f\"Loading model inputs for {s} {model_number}\")\n",
    "    # Update this file location accordingly on your local machine!\n",
    "    model_input_h5_fpath = f\"{h5_path}{s}_model_inputs.hdf5\"\n",
    "    tStims[s], tResps[s], vStims[s], vResps[s] = strf.load_model_inputs(model_input_h5_fpath, model_number)\n",
    "    print(s, model_number, \"t/v stim:\", tStims[s].shape, vStims[s].shape, \"||\",\n",
    "          \"t/v resp:\", tResps[s].shape, vResps[s].shape)\n",
    "# Load corrs, best alphas from pandas\n",
    "corrs, best_alphas = dict(), dict()\n",
    "results_csv_fpath = f\"{git_path}stats/lme_results.csv\"\n",
    "df = pd.read_csv(results_csv_fpath)\n",
    "pbar = tqdm(subjs)\n",
    "for s in pbar:\n",
    "    pbar.set_description(f\"Loading model outputs for {s} {model_number}\")\n",
    "    blockid = f\"{s}_B1\"\n",
    "    ch_names = mne.io.read_raw_brainvision(f\"{eeg_data_path}{s}/{blockid}/{blockid}_cca.vhdr\",\n",
    "                                           preload=False,verbose=False).info['ch_names']\n",
    "    subj_corrs, subj_best_alphas = np.zeros(len(ch_names)), np.zeros(len(ch_names))\n",
    "    for i,ch in enumerate(ch_names):\n",
    "        tgt_row = df[(df['subject']==s) & (df['model']==model_number) & (df['channel']==ch)]\n",
    "        subj_corrs[i] = df.loc[tgt_row.index, 'r_value']\n",
    "        subj_best_alphas[i] = df.loc[tgt_row.index, 'best_alpha']\n",
    "    corrs[s] = np.array(subj_corrs)\n",
    "    best_alphas[s] = np.array(subj_best_alphas) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d2fe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap data\n",
    "pvals = dict()\n",
    "nboots_shuffle = 100\n",
    "chunklen = len(delays)*3 # data randomized in chunks\n",
    "for s in subjs:\n",
    "    nsamps, nelecs = tResps[s].shape\n",
    "    allinds = range(nsamps)\n",
    "    nchunks = int(np.floor(0.2*nsamps/chunklen))\n",
    "    boot_corrs = []\n",
    "    # Run the bootstrap\n",
    "    pbar = tqdm(np.arange(nboots_shuffle))\n",
    "    for n in pbar:\n",
    "        pbar.set_description(f'{s} {model_number} Bootstrap {n}/{nboots_shuffle}')\n",
    "        indchunks = list(zip(*[iter(allinds)]*chunklen))\n",
    "        random.shuffle(indchunks)\n",
    "        shuff_inds = list(itools.chain(*indchunks[:nchunks]))\n",
    "        tStim_shuff = tStims[s].copy()\n",
    "        tResp_shuff = tResps[s].copy()\n",
    "        tStim_shuff = tStim_shuff[shuff_inds,:]\n",
    "        tResp_shuff = tResp_shuff[:len(shuff_inds),:]\n",
    "        boot_corr = eigridge_corr(tStim_shuff, vStims[s], tResp_shuff, vResps[s],\n",
    "                             [best_alphas[s][0]], corrmin = 0.05)\n",
    "        boot_corrs.append(boot_corr)\n",
    "    boot_corrs = np.vstack((boot_corrs))\n",
    "    # Compare bootstrap coors to STRF corrs\n",
    "    # Is the correlation of the model greater than the shuffled correlation for random data?\n",
    "    strf_corrs = corrs[s]\n",
    "    h_val = np.array([strf_corrs > boot_corrs[c] for c in np.arange(len(boot_corrs))])\n",
    "    print(h_val.shape) # Should be nboots x nchans\n",
    "    # Count the number of times out of nboots_shuffle that the correlation is greater than \n",
    "    # random, subtract from 1 to get the bootstrapped p_val (one per electrode)\n",
    "    pvals[s] = 1-h_val.sum(0)/nboots_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e584adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save bootstrap results to csv\n",
    "df = pd.read_csv(results_csv_fpath)\n",
    "pbar = tqdm(subjs)\n",
    "for s in pbar:\n",
    "    pbar.set_description(f\"Saving pvals for {s} {model_number} to csv\")\n",
    "    blockid = f\"{s}_B1\"\n",
    "    ch_names = mne.io.read_raw_brainvision(f\"{eeg_data_path}{s}/{blockid}/{blockid}_cca.vhdr\",\n",
    "                                           preload=False,verbose=False).info['ch_names']\n",
    "    for i,ch in enumerate(ch_names):\n",
    "        tgt_row = df[(df['subject']==s) & (df['model']==model_number) & (df['channel']==ch)]\n",
    "        df.loc[tgt_row.index, 'p_value'] = pvals[s][i]\n",
    "df.to_csv(results_csv_fpath,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
