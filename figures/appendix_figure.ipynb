{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa9da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import h5py\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib import cm\n",
    "from matplotlib import rcParams as rc\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn\n",
    "plt.style.use('seaborn')\n",
    "import csv\n",
    "import numpy as np\n",
    "rc['pdf.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7ffaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these path for running the notebook locally\n",
    "eeg_data_path = '/path/to/dataset/' # downloadable from OSF: https://doi.org/10.17605/OSF.IO/FNRD9\n",
    "git_path  = '/path/to/git/speaker_induced_suppression_EEG/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a143f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "click_color = \"#973DC2\"\n",
    "aux_color = \"#D24E2D\"\n",
    "perception_color = '#117733'\n",
    "production_color = '#332288'\n",
    "picks = ['F1','Fz','F2','FC1','FCz','FC2','C1','Cz','C2']\n",
    "tmin,tmax = -.2,.5\n",
    "reject_thresh = 5 # SD\n",
    "exclude = 'OP0020'\n",
    "subjs = np.sort([s[-6:] for s in glob(f'{git_path}eventfiles/*') if 'OP0' in s and exclude not in s])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fe639f",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4d450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_bads(subj,block,raw,git_path,eeg_data_path):\n",
    "    '''\n",
    "    CCA .vhdr files do not include bad channels, so this func interpolates them.\n",
    "    The end result is each subject has a 64 channel raw arrray, which makes plotting easier\n",
    "    Filter the data before running this!\n",
    "    '''\n",
    "    blockid = subj + '_' + block\n",
    "    nsamps = len(raw)\n",
    "    info = mne.io.read_raw_brainvision(f'{eeg_data_path}OP0001/OP0001_B1/OP0001_B1_cca.vhdr',\n",
    "                                           preload=False,verbose=False).info\n",
    "    ch_names = info['ch_names']\n",
    "    bads = [c for c in ch_names if c not in raw.info['ch_names']]\n",
    "    if len(bads) > 0:\n",
    "        new_data = []\n",
    "        for ch in ch_names:\n",
    "            if ch in bads:\n",
    "                print('Interpolating', ch)\n",
    "                new_data.append(np.zeros((1,nsamps)))\n",
    "            else:\n",
    "                new_data.append(raw.get_data(picks=ch)[0])\n",
    "        raw = mne.io.RawArray(np.vstack(new_data),info)\n",
    "        raw.info['bads'] = bads\n",
    "        raw.interpolate_bads()\n",
    "    else:\n",
    "        print(subj, 'has no bads.')\n",
    "    return raw\n",
    "def reject_epochs(raw,events,tmin,tmax,reject_thresh=10,picks=None):\n",
    "    \"\"\"\n",
    "    Get reject threshold\n",
    "    \"\"\"\n",
    "    reject = mne.Epochs(raw,events,tmin=tmin,tmax=tmax,reject=None,baseline=(None,0),verbose=False, event_repeated='drop')\n",
    "    if picks == None:\n",
    "        picks = mne.pick_types(raw.info,meg=False,eeg=True,eog=False)\n",
    "    reject = reject.get_data(picks=picks)\n",
    "    return dict(eeg=np.std(reject)*(reject_thresh)*2)\n",
    "def butter_highpass(cutoff, fs, order=5):\n",
    "    '''\n",
    "    Creates a high pass filter at a given frequency.\n",
    "    '''\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = scipy.signal.butter(order, normal_cutoff, btype='high', analog=False)\n",
    "    return b, a\n",
    "def butter_highpass_filter(data, cutoff, fs, order=2):\n",
    "    '''\n",
    "    Highpass filters data using a highpass filter.\n",
    "    '''\n",
    "    b, a = butter_highpass(cutoff, fs, order=order)\n",
    "    y = scipy.signal.filtfilt(b, a, data,axis=0)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f996a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "raws,infos = dict(),dict()\n",
    "for subj in tqdm(subjs):\n",
    "    blockid = subj + '_B1'\n",
    "    # get raw\n",
    "    raw_path = f'{eeg_data_path}{subj}/{blockid}/{blockid}_downsampled.vhdr'\n",
    "    raws[subj] = mne.io.read_raw_brainvision(raw_path,preload=True,verbose=False)\n",
    "    raws[subj].set_eeg_reference(['TP9','TP10'],verbose=False)\n",
    "    raws[subj].notch_filter(60,verbose=False)\n",
    "    raws[subj].filter(l_freq=1,h_freq=30,verbose=True)\n",
    "    # find bad channels and interpolate them so that each subj has 64 chans\n",
    "    raws[subj] = interpolate_bads(subj,block,raws[subj],git_path,eeg_data_path)\n",
    "    infos[subj] = raws[subj].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc465c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ccad data\n",
    "ccas = dict()\n",
    "for subj in tqdm(subjs):\n",
    "    blockid = subj + '_B1'\n",
    "    # get raw\n",
    "    cca_path = f'{eeg_data_path}{subj}/{blockid}/{blockid}_cca.vhdr'\n",
    "    ccas[subj] = mne.io.read_raw_brainvision(cca_path,preload=True,verbose=False)\n",
    "    ccas[subj].filter(l_freq=1,h_freq=30,verbose=False)\n",
    "    # find bad channels and interpolate them so that each subj has 64 chans\n",
    "    ccas[subj] = interpolate_bads(subj,block,ccas[subj],git_path,eeg_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34267925",
   "metadata": {},
   "source": [
    "### Epoch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67dfafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMG epochs\n",
    "raw_emg,cca_emg = dict(),dict()\n",
    "emg_resp = dict()\n",
    "emg_events = dict()\n",
    "reject_thresh = 5 # 10 SD\n",
    "for subj in tqdm(subjs):\n",
    "    print(subj)\n",
    "    emg_events[subj] = mne.preprocessing.find_eog_events(raws[subj],ch_name='hEOG',verbose=False,l_freq=1,h_freq=30)\n",
    "    # raw\n",
    "    reject = reject_epochs(raws[subj],emg_events[subj],tmin,tmax,reject_thresh=reject_thresh,picks=picks)\n",
    "    epochs = mne.Epochs(raws[subj],emg_events[subj],tmin=tmin,tmax=tmax,reject=reject,\n",
    "                        verbose=True,reject_by_annotation=False,proj=False,flat=None)\n",
    "    raw_emg[subj] = epochs.get_data(picks=picks)\n",
    "    emg_resp[subj] = epochs.get_data(picks='hEOG')\n",
    "\n",
    "    # cca\n",
    "    reject = reject_epochs(ccas[subj],emg_events[subj],tmin,tmax,reject_thresh=reject_thresh,picks=picks)\n",
    "    epochs = mne.Epochs(ccas[subj],emg_events[subj],tmin=tmin,tmax=tmax,reject=reject,\n",
    "                        verbose=True,reject_by_annotation=False,proj=False,flat=None)\n",
    "    cca_emg[subj] = epochs.get_data(picks=picks)\n",
    "    if subj in ['OP0016']: # cut off last epoch\n",
    "        cca_emg[subj] = cca_emg[subj][:-1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a2cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click epochs\n",
    "raw_click, cca_click = dict(),dict()\n",
    "click_events = dict()\n",
    "for subj in tqdm(subjs):\n",
    "    click_event_file = git_path + 'eventfiles/%s/%s_B1/%s_B1_click_eve.txt' % (\n",
    "        subj,subj,subj)\n",
    "    evs = np.loadtxt(click_event_file,dtype='f',usecols=(0,1,2))\n",
    "    evs[:,:2] = evs[:,:2]*128\n",
    "    click_events[subj] = np.array(evs,dtype=np.int)\n",
    "    # raw\n",
    "    reject = reject_epochs(raws[subj],click_events[subj],tmin,tmax,reject_thresh=reject_thresh,picks=picks)\n",
    "    epochs = mne.Epochs(raws[subj],click_events[subj],tmin=tmin,tmax=tmax,reject=reject,verbose=False)\n",
    "    raw_click[subj] = epochs.get_data(picks=picks)\n",
    "    # cca\n",
    "    reject = reject_epochs(ccas[subj],click_events[subj],tmin,tmax,reject_thresh=reject_thresh,picks=picks)\n",
    "    epochs = mne.Epochs(ccas[subj],click_events[subj],tmin=tmin,tmax=tmax,reject=reject,verbose=False)\n",
    "    cca_click[subj] = epochs.get_data(picks=picks)\n",
    "\n",
    "# Load click audio (for plotting)\n",
    "aud_onsets = np.array((click_events['OP0007'][:,0]/128)*25000).astype(int)\n",
    "aud_offsets =np.array((click_events['OP0007'][:,1]/128)*25000).astype(int)\n",
    "click_events_25k = np.array((aud_onsets,aud_offsets,click_events['OP0007'][:,2])).T\n",
    "audio_fpath = f'{eeg_data_path}OP0007/OP0007_B1/OP0007_B1_audio.vhdr'\n",
    "raw_audio = mne.io.read_raw_brainvision(audio_fpath, preload=True, verbose=False)\n",
    "click_epochs = mne.Epochs(raw_audio,click_events_25k,tmin=tmin,tmax=tmax,reject=None,\n",
    "                         baseline=(None,0),verbose=False)\n",
    "click_resp = click_epochs.get_data(picks=['spkr','mic'])\n",
    "click_resp = butter_highpass_filter(click_resp.T,10,raw_audio.info['sfreq']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e28b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perception and production epochs\n",
    "raw_spkr, cca_spkr = dict(), dict()\n",
    "raw_mic, cca_mic = dict(),dict()\n",
    "spkr_events,mic_events = dict(),dict()\n",
    "for subj in tqdm(subjs):\n",
    "    # Perc\n",
    "    spkr_event_file = f\"{git_path}eventfiles/{subj}/{subj}_B1/{subj}_B1_spkr_sn_all.txt\"\n",
    "    this_event = []\n",
    "    with open(spkr_event_file,'r') as f:\n",
    "        r = csv.reader(f,delimiter='\\t')\n",
    "        for row in r:\n",
    "            this_event.append(row[:3])\n",
    "    event_samples = np.array(this_event,dtype=np.float)\n",
    "    event_samples[:,:2] = np.round(event_samples[:,:2]*128)\n",
    "    spkr_events[subj] = event_samples.astype(np.int)\n",
    "    # raw\n",
    "    reject = reject_epochs(raws[subj],spkr_events[subj],tmin,tmax,reject_thresh=reject_thresh,picks=picks)\n",
    "    epochs = mne.Epochs(raws[subj],spkr_events[subj],tmin=tmin,tmax=tmax,reject=reject,verbose=False)\n",
    "    raw_spkr[subj] = epochs.get_data(picks=picks)\n",
    "    # cca\n",
    "    reject = reject_epochs(ccas[subj],spkr_events[subj],tmin,tmax,reject_thresh=reject_thresh,picks=picks)\n",
    "    epochs = mne.Epochs(ccas[subj],spkr_events[subj],tmin=tmin,tmax=tmax,reject=reject,verbose=False)\n",
    "    cca_spkr[subj] = epochs.get_data(picks=picks)\n",
    "    # Prod\n",
    "    mic_event_file = f\"{git_path}eventfiles/{subj}/{subj}_B1/{subj}_B1_mic_sn_all.txt\"\n",
    "    this_event = []\n",
    "    with open(mic_event_file,'r') as f:\n",
    "        r = csv.reader(f,delimiter='\\t')\n",
    "        for row in r:\n",
    "            this_event.append(row[:3])\n",
    "    event_samples = np.array(this_event,dtype=np.float)\n",
    "    event_samples[:,:2] = np.round(event_samples[:,:2]*128)\n",
    "    mic_events[subj] = event_samples.astype(np.int)\n",
    "    # raw\n",
    "    reject = reject_epochs(raws[subj],mic_events[subj],tmin,tmax,reject_thresh=reject_thresh,picks=picks)\n",
    "    epochs = mne.Epochs(raws[subj],mic_events[subj],tmin=tmin,tmax=tmax,reject=reject,verbose=False)\n",
    "    raw_mic[subj] = epochs.get_data(picks=picks)\n",
    "    # cca\n",
    "    reject = reject_epochs(ccas[subj],mic_events[subj],tmin,tmax,reject_thresh=reject_thresh,picks=picks)\n",
    "    epochs = mne.Epochs(ccas[subj],mic_events[subj],tmin=tmin,tmax=tmax,reject=reject,verbose=False)\n",
    "    cca_mic[subj] = epochs.get_data(picks=picks)\n",
    "    \n",
    "# Load sentence audio (for plotting)\n",
    "aud_onsets = np.array((mic_events['OP0007'][:,0]/128)*25000).astype(int)\n",
    "aud_offsets =np.array((mic_events['OP0007'][:,1]/128)*25000).astype(int)\n",
    "sen_events_25k = np.array((aud_onsets,aud_offsets,mic_events['OP0007'][:,2])).T\n",
    "audio_fpath = f'{data_path}OP0007/OP0007_B1/OP0007_B1_audio.vhdr'\n",
    "raw_audio = mne.io.read_raw_brainvision(audio_fpath, preload=True, verbose=False)\n",
    "sen_epochs = mne.Epochs(raw_audio,sen_events_25k,tmin=tmin,tmax=tmax,reject=None,\n",
    "                         baseline=(None,0),verbose=False)\n",
    "sen_resp = sen_epochs.get_data(picks=['mic'])\n",
    "sen_resp = butter_highpass_filter(sen_resp.T,10,raw_audio.info['sfreq']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e425c36",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fe4533",
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize=16\n",
    "fig = plt.figure(figsize=(9,11))\n",
    "gs = GridSpec(16, 8, figure=fig)\n",
    "ax = []\n",
    "x = np.linspace(tmin,tmax,raw_emg['OP0007'].shape[2])\n",
    "ax.append(fig.add_subplot(gs[0:2,:4]))\n",
    "sn_x = np.linspace(tmin,tmax,sen_resp.shape[2])\n",
    "plt.plot(sn_x,sen_resp[12][0],color=mic_color)\n",
    "plt.grid(False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.gca().set_facecolor('w')\n",
    "plt.title(\"Production\",fontsize=fontsize, loc='left', color=mic_color)\n",
    "\n",
    "ax.append(fig.add_subplot(gs[2:4,:4]))\n",
    "s = 'OP0007' \n",
    "plt.plot(x, emg_resp[s].mean(0)[0],color=aux_color);\n",
    "plt.grid(False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.gca().set_facecolor('w')\n",
    "plt.title(\"EMG Peak\", fontsize=fontsize, loc='left', color=aux_color)\n",
    "\n",
    "ax.append(fig.add_subplot(gs[0:2,4:]))\n",
    "sn_x = np.linspace(tmin,tmax,sen_resp.shape[2])\n",
    "plt.plot(sn_x,sen_resp[12][0],color=spkr_color)\n",
    "plt.grid(False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.gca().set_facecolor('w')\n",
    "plt.title(\"Perception\",fontsize=fontsize, loc='left', color=spkr_color)\n",
    "\n",
    "ax.append(fig.add_subplot(gs[2:4,4:]))\n",
    "click_x = np.linspace(tmin,tmax,click_resp.shape[2])\n",
    "plt.plot(click_x,click_resp[0][0],color=click_color)\n",
    "plt.grid(False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.gca().set_facecolor('w')\n",
    "plt.title(\"Click\",fontsize=fontsize, loc='left', color=click_color)\n",
    "\n",
    "ax.append(fig.add_subplot(gs[4:10,:4]))\n",
    "plt.ylabel(\"µV±σ\",fontsize=fontsize)\n",
    "y = np.vstack(list(raw_emg.values())).mean(1)/1e-6\n",
    "gplt.errorbars(x,y,color=aux_color)\n",
    "y = np.vstack(list(raw_mic.values())).mean(1)/1e-6\n",
    "gplt.errorbars(x,y,color=mic_color)\n",
    "plt.gca().set_xlim([tmin,tmax])\n",
    "plt.xticks([tmin,0,0.2,0.5,tmax],fontsize=fontsize)\n",
    "plt.yticks([-20,0,20,40,60],fontsize=fontsize)\n",
    "plt.gca().set_ylim([-20,60])\n",
    "plt.gca().set_xticklabels([])\n",
    "plt.title(\" \", fontsize=fontsize)\n",
    "\n",
    "\n",
    "ax.append(fig.add_subplot(gs[4:10,4:]))\n",
    "y = np.vstack(list(raw_click.values())).mean(1)/1e-6\n",
    "gplt.errorbars(x,y,color=click_color)\n",
    "plt.gca().set_xlim([tmin,tmax])\n",
    "y = np.vstack(list(raw_spkr.values())).mean(1)/1e-6\n",
    "gplt.errorbars(x,y,color=spkr_color)\n",
    "plt.xticks([tmin,0,0.2,0.5,tmax],fontsize=fontsize)\n",
    "plt.yticks([-20,0,20,40,60],fontsize=fontsize)\n",
    "plt.gca().set_ylim([-20,60])\n",
    "plt.gca().set_yticklabels([])\n",
    "plt.gca().set_xticklabels([])\n",
    "\n",
    "\n",
    "ax.append(fig.add_subplot(gs[10:,:4]))\n",
    "y = np.vstack(list(cca_emg.values())).mean(1)/1e-6\n",
    "gplt.errorbars(x,y,color=aux_color)\n",
    "y = np.vstack(list(cca_mic.values())).mean(1)/1e-6\n",
    "gplt.errorbars(x,y,color=mic_color)\n",
    "plt.gca().set_xlim([tmin,tmax])\n",
    "plt.xticks([tmin,0,0.2,0.5,tmax],fontsize=fontsize)\n",
    "plt.gca().set_ylim([-1.5,3.5])\n",
    "plt.yticks([-1,0,1,2,3],fontsize=fontsize)\n",
    "plt.ylabel(\"µV±σ\",fontsize=fontsize)\n",
    "plt.xlabel(\"Time (s)\", fontsize=fontsize)\n",
    "plt.title(\" \", fontsize=fontsize)\n",
    "\n",
    "\n",
    "ax.append(fig.add_subplot(gs[10:,4:]))\n",
    "y = np.vstack(list(cca_click.values())).mean(1)/1e-6\n",
    "gplt.errorbars(x,y,color=click_color)\n",
    "y = np.vstack(list(cca_spkr.values())).mean(1)/1e-6\n",
    "gplt.errorbars(x,y,color=spkr_color)\n",
    "plt.gca().set_xlim([tmin,tmax])\n",
    "plt.xticks([tmin,0,0.2,0.5,tmax],fontsize=fontsize)\n",
    "plt.gca().set_ylim([-1.5,3.5])\n",
    "plt.yticks([-1,0,1,2,3],fontsize=fontsize)\n",
    "plt.gca().set_yticklabels([])\n",
    "plt.xlabel(\"Time (s)\", fontsize=fontsize)\n",
    "\n",
    "plt.gcf().text(0.53,0.383,\"CCA data\", fontsize=fontsize, ha='center')\n",
    "plt.gcf().text(0.53,0.733,\"Raw data\", fontsize=fontsize, ha='center')\n",
    "\n",
    "gs.tight_layout(figure=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1a484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,2))\n",
    "for i,c in enumerate(colors):\n",
    "    plt.bar(0,0,color=c,label=labels[i])\n",
    "plt.grid(False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.legend(fontsize=fontsize,loc='center');\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
